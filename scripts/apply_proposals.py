#!/usr/bin/env python3
import os
import sys
import json
import jsonlines
import logging
from pathlib import Path
from datetime import datetime
from neo4j import GraphDatabase

# Setup Paths
BASE_DIR = Path(__file__).parent.parent
sys.path.append(str(BASE_DIR))

# Config
DATA_DIR = BASE_DIR / "data"
PROPOSALS_DIR = DATA_DIR / "proposals"
ARCHIVE_DIR = PROPOSALS_DIR / "archive"

NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "menir123")

# Logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger("menir_applicator")

def get_driver():
    return GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASSWORD))

def proposal_already_applied(tx, proposal_id):
    """Check if proposal ID exists in ProposalLog."""
    result = tx.run("MATCH (l:ProposalLog {id: $pid}) RETURN l", pid=proposal_id)
    return result.single() is not None

def apply_node_op(tx, node_op):
    """Execute dynamic Node MERGE/SET."""
    # naive implementation for V1 generic nodes
    # Expects: {"id": "uid", "labels": ["Label"], "properties": {...}}
    labels = ":".join(node_op.get("labels", []))
    props = node_op.get("properties", {})
    uid = node_op.get("id")
    
    if not labels or not uid:
        logger.warning(f"Skipping invalid node op: {node_op}")
        return

    # Dynamic Cypher construction (Be careful with injection if public, but this is internal tool)
    # We use params for values, but label string must be sanitized or trusted.
    # Assuming trusted proposals for now.
    query = f"MERGE (n:`{labels}` {{id: $uid}}) SET n += $props" # Corrected string interpolation
    # Fix: labels list might not work as label param directly in Cypher without APOC.
    # We construct the Label string. If multiple labels, this needs loop logic or APOC.
    # Simplified: Assume primary label for now or use APOC labels.
    # Let's handle list of labels:
    label_str = ":".join([f"`{l}`" for l in node_op.get("labels", [])])
    
    cypher = f"MERGE (n:{label_str} {{id: $uid}}) SET n += $props"
    tx.run(cypher, uid=uid, props=props)

def apply_rel_op(tx, rel_op):
    """Execute dynamic Relationship MERGE."""
    # Expects: {"source": "uid1", "target": "uid2", "type": "REL_TYPE", "properties": {}}
    src = rel_op.get("source")
    tgt = rel_op.get("target")
    rtype = rel_op.get("type")
    props = rel_op.get("properties", {})
    
    cypher = f"""
    MATCH (a {{id: $src}}), (b {{id: $tgt}})
    MERGE (a)-[r:`{rtype}`]->(b)
    SET r += $props
    """
    tx.run(cypher, src=src, tgt=tgt, props=props)

def apply_proposal_tx(tx, data):
    proposal_id = data.get("proposal_id")
    if not proposal_id:
        raise ValueError("Proposal missing ID")
        
    if proposal_already_applied(tx, proposal_id):
        logger.warning(f"Skipping {proposal_id} (Already Applied)")
        return False

    logger.info(f"Applying Proposal {proposal_id}...")
    
    # Apply Nodes
    for node in data.get("nodes", []):
        apply_node_op(tx, node)
        
    # Apply Relationships
    for rel in data.get("relationships", []):
        apply_rel_op(tx, rel)
        
    # Create Log
    tx.run("""
        CREATE (:ProposalLog {
            id: $pid, 
            applied_at: datetime(), 
            project_id: $proj,
            type: $type
        })
    """, pid=proposal_id, proj=data.get("project_id"), type=data.get("type"))
    
    return True

def process_file(filepath: Path, driver, commit: bool):
    """Read file, process content, manage state."""
    logger.info(f"Reading {filepath.name}...")
    
    try:
        with jsonlines.open(filepath) as reader:
            proposals = list(reader)
    except Exception as e:
        logger.error(f"Failed to parse {filepath}: {e}")
        return

    if not proposals:
        logger.info("Empty file.")
        return

    # In V1, each file contains 1 proposal object usually, but could be list.
    # Proposals generated by Server are single objects.
    data = proposals[0] # Assume one per file for now based on Server design
    
    if data.get("status") == "applied":
        logger.info("Skipping (Status applied inside file logic, though we use archive dir separate)")
        return

    if commit:
        with driver.session() as session:
            try:
                result = session.execute_write(apply_proposal_tx, data)
                if result:
                    logger.info("✅ Applied successfully.")
                    # Move to archive
                    ARCHIVE_DIR.mkdir(parents=True, exist_ok=True)
                    new_path = ARCHIVE_DIR / filepath.name
                    filepath.rename(new_path)
                    logger.info(f"Archived to {new_path}")
            except Exception as e:
                logger.error(f"❌ Transaction failed: {e}")
    else:
        logger.info(f"Dry Run: Would apply {data.get('proposal_id')} ({len(data.get('nodes', []))} nodes)")

def main():
    import argparse
    parser = argparse.ArgumentParser(description="Menir Proposal Applicator")
    parser.add_argument("--commit", action="store_true", help="Commit changes to DB")
    parser.add_argument("--file", help="Specific file to apply")
    args = parser.parse_args()

    # Check Proposals Dir
    if not PROPOSALS_DIR.exists():
        logger.info("No proposals directory found.")
        return

    files = [Path(args.file)] if args.file else list(PROPOSALS_DIR.glob("*.jsonl"))
    
    if not files:
        logger.info("No pending proposals found.")
        return

    driver = get_driver()
    try:
        driver.verify_connectivity()
    except Exception as e:
        logger.error(f"Cannot connect to Neo4j: {e}")
        return

    for f in files:
        if f.is_file():
            process_file(f, driver, args.commit)
            
    driver.close()

if __name__ == "__main__":
    main()
